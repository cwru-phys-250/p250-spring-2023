{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre Lab 11 : Markov Chains\n",
    "\n",
    "## Objectives\n",
    "\n",
    "Study one use of random numbers: random processes in the form of Markov Chains.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Course Evaluations\n",
    "\n",
    "Complete the course evaluations at this link: [Course Evaluations](https://webapps.case.edu/courseevals/). (Do so for all your courses, not just this one!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "\n",
    "As always you should add initialization to the top of your notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3bdd7cf2fb48f4a78f63fa46b050ab7e",
     "grade": true,
     "grade_id": "cell-c7b46068581f0fd0",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markov Chains\n",
    "\n",
    "A Markov chain (strictly speaking the discrete time Markov chain) describes a random process in which a system evolves by moving among a set of allowed states with given probabilities. It has the added property that it is \"memory-less\"; the probability of moving from one state to another does not depend on the previous states visited.\n",
    "\n",
    "### Where they appear\n",
    "\n",
    "Many physical processes can be described by Markov chains. Applications are extremely far-reaching, spanning many disciplines and areas of research. Examples of applications of Markov chains include search engine rankings, financial market behavior, and even simulations of brain activity. See the [Wikipedia page](http://en.wikipedia.org/wiki/Markov_chain#Applications) for a list of a few more examples. Numerous extensions to the simple model of a Markov chain presented here also exist, some of which are discussed on the Wikipedia page. One extension you may have heard of are [Markov chain Monte Carlo](http://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo) simulations, which combines Monte Carlo techniques mentioned in class and the lab with Markov chain techniques.\n",
    "\n",
    "Due to the probabilistic nature of Markov chains, they frequently appear in physics in statistical and thermodynamic systems. Here we will look at a couple of examples of Markov chains in order to predict the behavior of a simple system.\n",
    "\n",
    "### Defining the model\n",
    "\n",
    "Markov chains model systems as a set of discrete states with some probability of transitioning from one state to another (including the possibility of remaining in the original state). At any given time there will be some probability of being in any one of the allowed states. Let this set of probabilities be represented by a vector $\\vec{q}$. As a simple example, let us consider a 3-state system, which we can write as $\\vec{q} = (q_1, q_2, q_3)$. Since this is a set of probabilities and we must be in one of the states, the sum of the components of this vector must be unity. When in a given state there will be some probability of transitioning to another state: let us call $P_{i \\rightarrow j}$ the probability of transitioning from state $i$ to state $j$. We can represent the transition probabilities for a 3 state system as\n",
    "![Markov Chain States](https://raw.githubusercontent.com/cwru-phys-250/p250-spring-2023/main/figures/states.png)\n",
    "\n",
    "As an example of these ideas suppose we initially begin in state $1$ with probability $q_1^i = 1$. This is represented by the initial state vector $\\vec{q}^i = (1,0,0)$. Then the probability of transitioning to state $3$ is given by $P_{1 \\rightarrow 3}$ and similarly for the other states. So after one time step the state vector will be $\\vec{q}^f = (P_{1 \\rightarrow 1},P_{1 \\rightarrow 2},P_{2 \\rightarrow 3})$. We can perform a similar calculation for the other initial states (starting in state 2 or state 3 with probability one). The general evolution of the state vector in a Markov chain can be represented by a set of linear equations, which we can write in matrix form as\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "q_{1}^{f}\\\\\n",
    "q_{2}^{f}\\\\\n",
    "q_{3}^{f}\n",
    "\\end{pmatrix}\n",
    "=\n",
    "\\begin{pmatrix}\n",
    "P_{1\\rightarrow1} & P_{2\\rightarrow1} & P_{3\\rightarrow1}\\\\\n",
    "P_{1\\rightarrow2} & P_{2\\rightarrow2} & P_{3\\rightarrow2}\\\\\n",
    "P_{1\\rightarrow3} & P_{2\\rightarrow3} & P_{3\\rightarrow3}\n",
    "\\end{pmatrix} \n",
    "\\begin{pmatrix}\n",
    "q_{1}\\\\\n",
    "q_{2}\\\\\n",
    "q_{3}\n",
    "\\end{pmatrix}.\n",
    "$$\n",
    "\n",
    "Analyzing the transition matrix, $\\mathsf{P}$, we can find a number of special properties. One of the intuitive properties is that each of its columns must sum to unity; this being nothing more than conservation of probability. A less obvious property is that the eigenvalues of the system will all be unity or less. Further, if all the states of the system are accessible after some number of state changes for all possible initial states, then there will be one eigenvalue exactly equal to one. This eigenvalue and its associated eigenvector will describe the behavior of the system after a large number of state changes.\n",
    "\n",
    "To better understand this we again let the system start in the initial state $\\vec{q}^i$. After one state change (one step in the Markov chain) the probability of being in any state will be $\\mathsf{P} \\vec{q}^i$. After another state change it will be $\\mathsf{P}^2 \\vec{q}^i$, and after $n$ changes it will be $\\mathsf{P}^n \\vec{q}^i$. Recall that we can raise a matrix to an arbitrary power by diagonalizing it, and raising the diagonal matrix to a power. This results in the relationship\n",
    "$$ \\mathsf{P}^n = \\mathsf{V} \\mathsf{D}^n \\mathsf{V}^{-1} $$\n",
    "where $\\mathsf{V}$ is a matrix whose columns are the eigenvectors of $\\mathsf{P}$ and $\\mathsf{D}$ is a matrix containing the corresponding eigenvalues along the diagonal.\n",
    "\n",
    "It is interesting to consider what happens in the $n \\rightarrow \\infty$ limit. Since one eigenvalue is unity and the rest smaller than one, taking the limit as $n \\rightarrow \\infty$ will result in all eigenvalues except the unitary one approaching zero. The eigenvector corresponding to this eigenvalue is somewhat special: if the probability of being in a given state is described by this eigenvector, after subsequent steps the probability of being in a state remains the same; while the probability of being in a state described by other eigenvectors will diminish. Thus after a long time, the probability of being in a given state will be described by the eigenvector corresponding to the unit eigenvalue. This vector is sometimes referred to as the **stationary state of the system**. After a long time, or equivalently many steps, the system will settle into its stationary state.\n",
    "\n",
    "## Cleveland Weather\n",
    "\n",
    "As a simple model of spring weather in Cleveland let us consider a 3-state system with the states representing a \"sunny\" day, a \"rainy\" day, and a \"cloudy\" day. A more realistic model may include knowledge of weather at other locations, temperatures humidity; or a full-blown climate simulation. However for a simple example we will ignore the details. Let the probabilities of transitioning from one type of weather to another be given as in the following diagram:\n",
    "![Weather States](https://raw.githubusercontent.com/cwru-phys-250/p250-spring-2023/main/figures/weather_states.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the transition matrix $\\mathsf{P}$ that describes this diagram for the state vector\n",
    "$$\\vec{q} = \\begin{pmatrix} q_☼ \\\\ q_☂ \\\\ q_☁ \\end{pmatrix}.$$\n",
    "Verify that the columns of this matrix add up to one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5fb03b055d78e6204801bdaf4de404f4",
     "grade": true,
     "grade_id": "cell-9d679e004397575a",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform an eigenvalue decomposition of this matrix. You should find all the eigenvalues are real (even though $\\mathsf{P}$ is not symmetric) and one of them is unity. Print the eigenvector corresponding to the unit eigenvalue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "611590d3cc667da346febab1a4724073",
     "grade": true,
     "grade_id": "cell-a617357539ec696d",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is good, but this vector looks wrong.  It is suppose to represent probabilities and the sum must be one. It may also be the case that all the values are negative, so how could they be probabilities! The case of negative values can easily be fixed by multiplying the vector by negative one. (Recall why we are allowed to do this!) The other issue is due to how eigenvectors are normalized. (Again recall how this is done!) Since we have a physical meaning for the vector and its normalization we will need to renormalize it. (For different reasons and in a different manner we needed to renormalize the eigenvectors when we solved the Schrödinger equation in Lab 9.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Renormalize the eigenvector from the previous part so that its sum is one. Print the renormalized vector. (All the probabilities better be positive now!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1fbfbc570f33e8656e334ba7f2964221",
     "grade": true,
     "grade_id": "cell-4a8ce0e5829b005e",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use our simple model to forecast the weather. Given an initial state representing the weather today we can predict the probabilities of it being sunny, rainy, or cloudy after 1 day, 2 days, or 1 week. To begin pick an initial state vector representing the weather today\n",
    "$$ \\vec{q}^i = \\left( \\begin{array}{c} q_☼ \\\\ q_☂ \\\\ q_☁ \\end{array} \\right). $$\n",
    "Pick one that is somewhat representative of the weather when you are working on the prelab!\n",
    "\n",
    "In order to calculate the weather after one, two, and seven days you will need to calculate $\\mathsf{P} \\vec{q}^i$, $\\mathsf{P}^2 \\vec{q}^i$, and $\\mathsf{P}^7 \\vec{q}^i$. There are multiple ways to raise a matrix to a power. One way is to use the eigenvalue decomposition from above (and as discussed in homework 9). As an alternative, NumPy provides a function for doing this: `np.linalg.matrix_power`. Either of these methods is better than repeatedly multiplying the matrix with itself.\n",
    "\n",
    "Print the probabilities for the state of the weather after 1, 2, and 7 days. Note that after 7 days the result should look very much like the stationary state we found above. For fun you may want to compare your predictions to those from a professional weather service and/or keep track of you predictions and see how they turn out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b450d570d879b0cb6ef7ccc35b42147e",
     "grade": true,
     "grade_id": "cell-046bb3933be6f0db",
     "locked": false,
     "points": 0.75,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drunkard's Walk\n",
    "\n",
    "A random walk is another simple example of a Markov chain. Here we will work through a variant of the random walk where we add the special property that it is possible to get stuck in certain states. This is called an \"**absorbing chain**\" with the transition probabilities given in the diagram below.\n",
    "![Example of an absorbing chain](https://raw.githubusercontent.com/cwru-phys-250/p250-spring-2023/main/figures/absorbing_chain.png)\n",
    "\n",
    "We can consider this to represent the path taken by an inebriated individual as he attempts to locate either their home or another bar. In state 1 the drunkard reaches home and will remain there. In state 5 they reach another bar and again remains there. In between the two destinations they will stumble in either direction with probability $1/2$ (this equal probability step is the usual random walk behavior).\n",
    "\n",
    "Systems like this are special in that more than one eigenvalue is unity so there are multiple stationary states. (The assertion made above that all states should be accessible has been broken.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct the transition matrix, $\\mathsf{P}$, for this system.  Print the vectors representing the stationary states of the system. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9fd4ee02504505e99aff1163291f0d55",
     "grade": true,
     "grade_id": "cell-8b1bd7e5658bc02b",
     "locked": false,
     "points": 1.25,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The form of the stationary states make sense. Describe in words what they represent. Are all states accessible from all other states?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ee8398778e990de52c24996ca683addf",
     "grade": true,
     "grade_id": "cell-301e71f608c38c60",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many other interesting questions that could be asked. For example, suppose the drunkard starts in state labeled 2 in the figure, what is the probability they will end up at home? Similarly, what are the probabilities when starting in the states labeled 3 or 4? For each of these initial states we could also determine the average number of steps taken by the drunkard. Numerically these can be easily modeled using Monte Carlo techniques to simulate a drunkard walking from each initial state. We will not do so here, but feel free to explore it on your own."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turning in the PreLab\n",
    "\n",
    "All prelabs will be handled as was done for PreLab01. See that file for details. It will be assumed from now on that you have read and understood the procedure and what it means when you submit a prelab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "Craig J Copi",
    "semester": "Spring 2022"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
