{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eigenvalues and Eigenvectors\n",
    "\n",
    "Here we will study various functions for finding eigenvalues and eigenvectors. We will apply them to a few different types of matrices to better understand some of the claims made in class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.linalg as la"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the `scipy.linalg` module there are a number of functions for solving eigenvalue problems. These functions are roughly split into ones that only calculate the eigenvalues and ones that calculate both the eigenvalues and eigenvectors. We will be interested in finding both the eigenvalues and eigenvectors so will focus on that set of functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "la?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also as always we should look at the documentation for any and all functions that interest us. Here we look at a few. In the prelab and lab we will explore the use of `eig_banded`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "la.eig?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "la.eigh?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Matrix\n",
    "\n",
    "Let us use the matrix from the system of linear equations we solved last week. Recall that for this system\n",
    "$$\n",
    "\\mathsf{A} = \\begin{pmatrix}\n",
    "10 & -7 & 1 \\\\\n",
    "-3 & 2 & 6 \\\\\n",
    "5 & -1 & 5\n",
    "\\end{pmatrix} . $$\n",
    "We can find the eigenvalues and eigenvectors for this matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigenvalues: [-1.74671985+0.j          9.37335992+2.21029215j  9.37335992-2.21029215j]\n",
      "Matrix of eigenvectors:\n",
      " [[ 0.51077299+0.j         -0.68330542+0.j         -0.68330542-0.j        ]\n",
      " [ 0.82042522+0.j         -0.14949126+0.25215869j -0.14949126-0.25215869j]\n",
      " [-0.25693074+0.j         -0.61825225+0.25480624j -0.61825225-0.25480624j]]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[10, -7, 1.], [-3, 2, 6], [5, -1, 5]])\n",
    "(lam, B) = la.eig(A)\n",
    "print(\"Eigenvalues:\", lam)\n",
    "print(\"Matrix of eigenvectors:\\n\", B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First notice that the eigenvalues and eigenvectors can be complex even for a real matrix. NumPy for some reason has chosen to use the (electrical) engineering notation for complex numbers, $\\mathrm{j}\\equiv\\sqrt{-1}$ so complex numbers are of the form $x=\\alpha+\\beta\\mathrm{j}$ and represented in Python as \n",
    "```\n",
    "x = alpha + beta*1j\n",
    "```\n",
    "(notice the `1j`).\n",
    "\n",
    "Next, the columns in the matrix returned, called `B` here, represent each of the eigenvectors. These are normalized to have unit magnitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(np.sqrt(np.sum(np.abs(B)**2, axis=0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This matrix also diagonalizes $\\mathsf{A}$, so that\n",
    "$$ \\mathsf{B}^{-1}\\mathsf{A}\\mathsf{B} = \\left( \\begin{array}{ccc}\n",
    "\\lambda_1 & 0 & 0 \\\\\n",
    "0 & \\lambda_2 & 0 \\\\\n",
    "0 & 0 & \\lambda_3\n",
    "\\end{array} \\right). $$\n",
    "We can verify this. To compare the results we can either extract the diagonal from the result or construct a diagonal matrix from the eigenvalues, both are accomplished using the `np.diag` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binv A B =\n",
      " [[-1.74671985e+00-1.72563323e-31j  5.21804822e-15-1.66533454e-15j\n",
      "   4.66293670e-15+1.88737914e-15j]\n",
      " [ 2.78943535e-15-3.99680289e-15j  9.37335992e+00+2.21029215e+00j\n",
      "  -5.32907052e-15-1.77635684e-15j]\n",
      " [ 2.27595720e-15+3.10862447e-15j -4.44089210e-15+3.55271368e-15j\n",
      "   9.37335992e+00-2.21029215e+00j]]\n",
      "Matrix of eigenvalues? True\n"
     ]
    }
   ],
   "source": [
    "D = la.inv(B) @ A @ B\n",
    "print(\"Binv A B =\\n\", D)\n",
    "print(\"Matrix of eigenvalues?\", np.allclose(D, np.diag(lam)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the determinant of the matrix should be the product of the eigenvalues. The determinant of a real matrix is real, the product of the eigenvalues may have a small imaginary part due to finite precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Determinant = -162.00000000000003\n",
      "Product of eigenvalues = (-161.99999999999991+7.105427357601002e-15j)\n"
     ]
    }
   ],
   "source": [
    "print(\"Determinant =\", la.det(A))\n",
    "print(\"Product of eigenvalues =\", np.prod(lam))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Symmetric Matrix\n",
    "\n",
    "Next consider the symmetric matrix we studied in the lecture,\n",
    "$$ \\mathsf{A} = \\begin{pmatrix}\n",
    "5 & 0 & \\sqrt 3 \\\\\n",
    "0 & 1 & 0 \\\\\n",
    "\\sqrt 3 & 0 & 3\n",
    "\\end{pmatrix}. $$\n",
    "We will verify the results found in class.\n",
    "\n",
    "The eigenvalues and eigenvectors are calculated as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigenvalues: [6.+0.j 2.+0.j 1.+0.j]\n",
      "Matrix of eigenvectors:\n",
      " [[ 0.8660254 -0.5        0.       ]\n",
      " [ 0.         0.         1.       ]\n",
      " [ 0.5        0.8660254  0.       ]]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[5., 0, np.sqrt(3)], [0, 1, 0], [np.sqrt(3), 0, 3]])\n",
    "(lam, B) = la.eig(A)\n",
    "print(\"Eigenvalues:\", lam)\n",
    "print(\"Matrix of eigenvectors:\\n\", B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the eigenvalues and eigenvectors for a symmetric (or hermitian) matrix are real. For a such matrix we could instead use the specialized function `scipy.linalg.eigh`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigenvalues: [1. 2. 6.]\n",
      "Matrix of eigenvectors:\n",
      " [[ 0.         0.5        0.8660254]\n",
      " [-1.         0.         0.       ]\n",
      " [ 0.        -0.8660254  0.5      ]]\n"
     ]
    }
   ],
   "source": [
    "(lam, B) = la.eigh(A)\n",
    "print(\"Eigenvalues:\", lam)\n",
    "print(\"Matrix of eigenvectors:\\n\", B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The order of the results has changed!** Besides returning the eigenvalues as real numbers, instead of complex numbers with zero imaginary part, the order in which they are returned has changed. Here `eigh` chooses to sort the eigenvalues from smallest to largest. This means the eigenvectors must also change order since each eigenvector is associated with a particular eigenvalue. Of course the order cannot matter, but the order of the eigenvalues and eigenvectors must be consistent. Also notice that the sign of some of the eigenvectors has changed. In the eigenvalue problem, $\\mathsf{A}\\vec{v} = \\lambda \\vec{v}$ if $\\vec{v}$ is an eigenvector then so is $-\\vec{v}$. Again, the choice of sign is arbitrary. We see that different algorithms make different choices even for the same matrix.\n",
    "\n",
    "For a symmetric matrix the matrix of eigenvectors is orthogonal. This means that $\\mathsf{B}^T=\\mathsf{B}^{-1}$, so the inverse is trivial to calculate. We can test this in a few ways as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B^T = Binv? True\n",
      "B^T B = I? True\n",
      "B B^T = I? True\n"
     ]
    }
   ],
   "source": [
    "print(\"B^T = Binv?\", np.allclose(B.T, la.inv(B)))\n",
    "print(\"B^T B = I?\", np.allclose(B.T @ B, np.identity(B.shape[0])))\n",
    "print(\"B B^T = I?\", np.allclose(B @ B.T, np.identity(B.shape[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also verify that $\\mathsf{B}$ diagonalizes $\\mathsf{A}$. Since $\\mathsf{B}$ is orthogonal we now can write this more simply as\n",
    "$$ \\mathsf{B}^T \\mathsf{A}\\mathsf{B} = \\begin{pmatrix}\n",
    "\\lambda_1 & 0 & 0 \\\\\n",
    "0 & \\lambda_2 & 0 \\\\\n",
    "0 & 0 & \\lambda_3\n",
    "\\end{pmatrix}. $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B^T A B =\n",
      " [[ 1.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  2.00000000e+00  2.97483363e-17]\n",
      " [ 0.00000000e+00 -1.11022302e-16  6.00000000e+00]]\n",
      "Matrix of eigenvalues? True\n"
     ]
    }
   ],
   "source": [
    "D = B.T @ A @ B\n",
    "print(\"B^T A B =\\n\", D)\n",
    "print(\"Matrix of eigenvalues?\", np.allclose(D, np.diag(lam)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Degenerate Eigenvalues\n",
    "\n",
    "The eigenvalues do not need to be distinct. If two or more eigenvalues are equal they are called degenerate. The eigenvectors associated with these eigenvalues are not unique: any linear combination of them will also satisfy the eigenvalue problem. To see this let us consider a different symmetric matrix,\n",
    "$$ \\mathsf{A} = \\begin{pmatrix}\n",
    "5 & 0 & 2 \\\\\n",
    "0 & 1 & 0 \\\\\n",
    "2 & 0 & 2\n",
    "\\end{pmatrix}. $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigenvalues: [1. 1. 6.]\n",
      "Matrix of eigenvectors:\n",
      " [[ 0.          0.4472136   0.89442719]\n",
      " [-1.          0.          0.        ]\n",
      " [ 0.         -0.89442719  0.4472136 ]]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[5., 0, 2], [0, 1, 0], [2, 0, 2]])\n",
    "(lam, B) = la.eigh(A)\n",
    "print(\"Eigenvalues:\", lam)\n",
    "print(\"Matrix of eigenvectors:\\n\", B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the eigenvalue `1` appears twice. We can perform all the same tests from above to confirm that we have correctly solved the eigenvalue problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B^T = Binv? True\n",
      "B^T B = I? True\n",
      "B B^T = I? True\n",
      "B^T A B =\n",
      " [[1.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 1.00000000e+00 1.19692947e-15]\n",
      " [0.00000000e+00 6.78144704e-16 6.00000000e+00]]\n",
      "Matrix of eigenvalues? True\n"
     ]
    }
   ],
   "source": [
    "print(\"B^T = Binv?\", np.allclose(B.T, la.inv(B)))\n",
    "print(\"B^T B = I?\", np.allclose(B.T @ B, np.identity(B.shape[0])))\n",
    "print(\"B B^T = I?\", np.allclose(B @ B.T, np.identity(B.shape[0])))\n",
    "D = B.T @ A @ B\n",
    "print(\"B^T A B =\\n\", D)\n",
    "print(\"Matrix of eigenvalues?\", np.allclose(D, np.diag(lam)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These eigenvectors are not unique. If we call the eigenvectors found above $\\vec v_0$, $\\vec v_1$, and $\\vec v_2$ then due to the degeneracy we can construct another set of vectors by taking any linear combinations of the first two. (In practice we typically want the eigenvectors to be orthogonal so we should ensure this is true in our new set of eigenvectors.) For example, we can construct a new set as\n",
    "$$\n",
    "\\begin{align}\n",
    "\\vec v_0' &= \\frac{1}{\\sqrt 6}\\vec v_0 - \\sqrt{\\frac{5}{6}} \\vec v_1, \\\\\n",
    "\\vec v_1' &= \\sqrt{\\frac{5}{6}}\\vec v_0 + \\frac{1}{\\sqrt 6} \\vec v_1, \\\\\n",
    "\\vec v_2' &= \\vec v_2.\n",
    "\\end{align}$$\n",
    "Here $\\vec v_2'$ is the same as above, but the first two are different. We can verify this is also a valid set using the same tests as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alternate B =\n",
      " [[-0.40824829  0.18257419  0.89442719]\n",
      " [-0.40824829 -0.91287093  0.        ]\n",
      " [ 0.81649658 -0.36514837  0.4472136 ]]\n",
      "B^T = Binv? True\n",
      "B^T B = I? True\n",
      "B B^T = I? True\n",
      "B^T A B =\n",
      " [[ 1.00000000e+00  5.73807731e-17 -1.14964814e-15]\n",
      " [ 7.65209819e-17  1.00000000e+00  5.34720368e-16]\n",
      " [-9.91374242e-16  3.83317957e-16  6.00000000e+00]]\n",
      "Matrix of eigenvalues? True\n"
     ]
    }
   ],
   "source": [
    "Bp = np.zeros_like(B)\n",
    "Bp[:, 0] = 1/np.sqrt(6) * B[:, 0] - np.sqrt(5./6) * B[:, 1]\n",
    "Bp[:, 1] = np.sqrt(5./6) * B[:, 0] + np.sqrt(1./6) * B[:, 1]\n",
    "Bp[:, 2] = B[:, 2]\n",
    "print(\"Alternate B =\\n\", Bp)\n",
    "print(\"B^T = Binv?\", np.allclose(Bp.T, la.inv(Bp)))\n",
    "print(\"B^T B = I?\", np.allclose(Bp.T @ Bp, np.identity(Bp.shape[0])))\n",
    "print(\"B B^T = I?\", np.allclose(Bp @ Bp.T, np.identity(Bp.shape[0])))\n",
    "D = Bp.T @ A @ Bp\n",
    "print(\"B^T A B =\\n\", D)\n",
    "print(\"Matrix of eigenvalues?\", np.allclose(D, np.diag(lam)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
